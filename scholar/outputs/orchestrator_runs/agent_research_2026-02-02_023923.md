## Summary
Highest-value direction is to map missing telemetry to SOP steps, because no telemetry snapshot was provided and we need a baseline before prioritizing research. Flow: `Telemetry -> Gap -> Research -> SOP update`.

## Research Questions
- Which SOP steps currently lack measurable signals (e.g., session start/end, active-recall tasks, Anki export counts), so we can define the minimum events to capture?
- Which outcomes correlate most with progress in this system (exam scores, retention, time-to-competency), so research focuses on the highest-leverage SOP changes?
- Where are the largest drop-offs in the study workflow (capture -> process -> review), and what SOP changes reduce attrition?
- How reliable are current logs vs manual audits, so we know whether telemetry is trustworthy enough to guide SOP updates?
- What study-to-review timing yields best retention for PT coursework in this context, so scheduling SOP can be tuned?

## Proposed Evidence Sources
- Internal telemetry logs and DB tables (`brain/session_logs/`, `brain/data/pt_study.db`) to quantify gaps.
- SOP library (`sop/library/00-overview.md` through `sop/library/12-*.md`) to map steps to signals.
- Scholar summaries (`scholar/outputs/`) for already-curated learning science notes.
- External learning science sources on testing effect, spaced repetition, interleaving, and desirable difficulties.

## Initial Findings (if any)
- (none)

## Questions Needed
- What is the SOP scope allowlist for this run (which modules/steps are in-scope)?
- Where is the latest telemetry snapshot stored, and which tables/fields are canonical?
- What decision needs to be supported first (instrumentation, SOP edits, dashboard metrics)?
- Any time window or cohort focus (current semester, specific courses)?
- Any data access or privacy constraints I should assume?