#!/usr/bin/env python3
from __future__ import annotations

import re
import sys
from pathlib import Path
from typing import Iterable, List

VERSION = "9.5"

ROOT = Path(__file__).resolve().parents[2]
SOP_DIR = ROOT / "sop"
LIB_DIR = SOP_DIR / "library"
RUNTIME_DIR = SOP_DIR / "runtime"
UPLOAD_DIR = RUNTIME_DIR / "knowledge_upload"


def rel(path: Path) -> str:
    return path.relative_to(ROOT).as_posix()


def read_text(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def normalize(text: str) -> str:
    return text.replace("\r\n", "\n").replace("\r", "\n").strip()


def strip_relative_links(text: str) -> str:
    def repl(match: re.Match[str]) -> str:
        label = match.group(1)
        link = match.group(2)
        if re.match(r"^(https?://|mailto:)", link):
            return match.group(0)
        return label

    return re.sub(r"\[([^\]]+)\]\(([^)]+)\)", repl, text)


def replace_local_refs(text: str) -> str:
    replacements = {
        "sop/src/templates/retrospective_timetable.md": "retrospective timetable (see Templates section)",
        "sop/src/templates/post_lecture_elaboration_prompts.md": "post-lecture elaboration prompts (see Templates section)",
        "sop/logging_schema_v9.3.md": "logging schema (see Logging section)",
        "logging_schema_v9.3.md": "logging schema (see Logging section)",
        "sop/src/workload/rotational_interleaving_3plus2.md": "3+2 rotational interleaving (see M0 Planning)",
        "sop/master_rotational_interleaving_system.md": "3+2 rotational interleaving (see M0 Planning)",
        "09-templates.md": "Templates section",
        "06-modes.md": "Modes section",
    }
    for key, value in replacements.items():
        text = text.replace(key, value)
    return text


def sanitize(text: str) -> str:
    text = normalize(text)
    text = strip_relative_links(text)
    text = replace_local_refs(text)
    return text


def extract_section(text: str, heading: str) -> str:
    text = normalize(text)
    lines = text.split("\n")
    for i, line in enumerate(lines):
        if line.strip() == heading:
            level = len(line.split()[0])
            start = i
            end = len(lines)
            for j in range(i + 1, len(lines)):
                candidate = lines[j].strip()
                if candidate.startswith("#"):
                    candidate_level = len(candidate.split()[0])
                    if candidate_level <= level:
                        end = j
                        break
            return "\n".join(lines[start:end]).strip()
    raise ValueError(f"Heading not found: {heading}")


def join_sections(text: str, headings: Iterable[str]) -> str:
    return "\n\n".join(extract_section(text, heading) for heading in headings)


def find_wrap_heading(text: str) -> str:
    text = normalize(text)
    lines = text.split("\n")
    prefix = "## M6: Wrap"
    for line in lines:
        stripped = line.strip()
        if stripped.startswith(prefix):
            print(f"Wrap section found: {stripped}")
            return stripped
    raise ValueError(
        "M6 Wrap heading not found. Acceptable headings: "
        "'## M6: Wrap (Close and Schedule)', '## M6: Wrap', "
        "or any heading starting with '## M6: Wrap'."
    )


def render_header(filename: str, sources: List[Path]) -> str:
    sources_block = "\n".join(f"- {rel(path)}" for path in sources)
    return (
        f"# Runtime Bundle: {filename}\n"
        f"Version: v{VERSION}\n"
        "Generated by: sop/tools/build_runtime_bundle.py (deterministic)\n"
        f"Sources:\n{sources_block}\n\n---\n\n"
    )


def render_source_block(source_path: Path, content: str) -> str:
    return f"## Source: {rel(source_path)}\n\n{sanitize(content)}\n"


def write_output(path: Path, content: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content.strip() + "\n", encoding="utf-8")


def build_index_and_rules(core_rules: str, evidence: str) -> str:
    core_extract = join_sections(
        core_rules,
        [
            "## Session Rules",
            "## Content Rules",
            "## Evidence Nuance Rules",
            "## Logging Rules",
            "## No-Skip Rules (Summary)",
        ],
    )
    notebooklm = extract_section(evidence, "## NotebookLM Bridge")

    additions = """
## Source of Truth
- Canonical content lives in `sop/library/` and is read-only.
- Runtime files in `sop/runtime/knowledge_upload/` are generated. Do not edit them directly.

## Bundle Index (upload in order)
1) 00_INDEX_AND_RULES.md
2) 01_MODULES_M0-M6.md
3) 02_FRAMEWORKS.md
4) 03_ENGINES.md
5) 04_LOGGING_AND_TEMPLATES.md
6) 05_EXAMPLES_MINI.md

## Canonical Library Map (current filenames)
- 02-learning-cycle.md (PEIRRO + KWIK)
- 03-frameworks.md (H/M/Y/L)
- 04-engines.md
- 05-session-flow.md (M0-M6)
- 06-modes.md
- 08-logging.md
- 09-templates.md
- 11-examples.md
- 12-evidence.md

## Multi-Domain Topic Prefix + Engine Router (schema-safe)
- The `topic` field must be prefixed with: `[DPT]` or `[Startup]` or `[Other]`.
- Engine router:
  - If `[DPT]` and regional/spatial anatomy, use the Anatomy Engine.
  - Otherwise use the Concept Engine.
- Do not add new JSON keys for domain routing.

## UNVERIFIED Behavior (no refusal)
- If sources are missing or no NotebookLM Source Packet is provided, mark outputs **UNVERIFIED**.
- Limit output to strategy, questions, and planning until sources are provided.

## Dashboard Ingest: `anki_cards` Encoding
- Enhanced JSON field `anki_cards` is a semicolon-separated list.
- Each card uses the format: `Front|||Back|||TagsCSV|||Deck`.
- Avoid semicolons inside Front/Back.
- Deck may be `AUTO` to route by topic prefix.
"""

    return (
        sanitize(additions)
        + "\n\n"
        + render_source_block(LIB_DIR / "01-core-rules.md", core_extract)
        + "\n"
        + render_source_block(LIB_DIR / "12-evidence.md", notebooklm)
    )


def build_modules(session_flow: str, modes: str) -> str:
    wrap_heading = find_wrap_heading(session_flow)
    headings = [
        "## 60-Second Quick Start",
        "## M0: Planning",
        "## M1: Entry",
        "## M2: Prime (Map the Territory)",
        "## M3: Encode (Attach Meaning)",
        "## M4: Build (Practice and Transfer)",
        wrap_heading,
        "## Quick Reference: Session Flow",
    ]
    session_extract = join_sections(session_flow, headings)
    return (
        render_source_block(LIB_DIR / "05-session-flow.md", session_extract)
        + "\n"
        + render_source_block(LIB_DIR / "06-modes.md", modes)
    )


def build_frameworks(learning_cycle: str, frameworks: str) -> str:
    return (
        render_source_block(LIB_DIR / "02-learning-cycle.md", learning_cycle)
        + "\n"
        + render_source_block(LIB_DIR / "03-frameworks.md", frameworks)
    )


def build_engines(engines: str) -> str:
    router = """
## Engine Router (Multi-Domain)
- Topic prefix required: `[DPT]` / `[Startup]` / `[Other]`.
- If `[DPT]` and regional/spatial anatomy: use Anatomy Engine.
- Otherwise: use Concept Engine.
- This is a routing convention only; no schema keys are added.
"""
    return sanitize(router) + "\n\n" + render_source_block(LIB_DIR / "04-engines.md", engines)


def build_logging(logging: str, templates: str) -> str:
    additions = """
## Runtime Additions (v9.3)

### Topic Prefix (multi-domain)
- `topic` must start with `[DPT]`, `[Startup]`, or `[Other]`.

### Dashboard `anki_cards` Encoding
- `anki_cards` remains a semicolon-separated list.
- Each card entry is: `Front|||Back|||TagsCSV|||Deck`.
- Avoid semicolons inside Front/Back.
- Deck may be `AUTO` to route by topic prefix.
"""
    return (
        sanitize(additions)
        + "\n\n"
        + render_source_block(LIB_DIR / "08-logging.md", logging)
        + "\n"
        + render_source_block(LIB_DIR / "09-templates.md", templates)
    )


def build_examples(examples: str) -> str:
    headings = [
        "## Command Reference",
        "## Example: Session Start (Planning)",
        "## Example: Sprint Mode (Fail-First)",
        "## Example: Wrap Output",
    ]
    sections: list[str] = []
    missing: list[str] = []
    for heading in headings:
        try:
            sections.append(extract_section(examples, heading))
        except ValueError:
            missing.append(heading)
    if missing:
        print(
            "WARNING: Missing example headings: " + ", ".join(missing),
            file=sys.stderr,
        )
    extract = "\n\n".join(sections).strip()
    return render_source_block(LIB_DIR / "11-examples.md", extract)


def build_runtime_prompt() -> str:
    return sanitize(
        f"""Structured Architect v{VERSION} active.
Role: guide active construction; enforce planning gates; prevent phantom outputs; adapt to readiness.

## Non-negotiable rules
- Planning gate: Exposure Check first. No teaching until M0 is complete (Track A or Track B).
- Source-Lock: factual teaching requires learner sources; if missing -> label UNVERIFIED and do strategy/questions only.
- Seed-Lock (ask-first): you attempt seeds first; AI suggests only if you ask.
- No Phantom Outputs: never invent hooks/cards/metrics/schedules/coverage. If not done -> NOT DONE / UNKNOWN / NONE.
- Level gating: L2 teach-back before L4 detail.

## Pacing rules
- One-Step Rule: each message = exactly ONE question OR ONE micro-teach. Never both.
- Continuation: after your answer -> brief feedback -> next single step. Never stall or end without a next action.
- Default mode: FIRST EXPOSURE (teach-first) unless you say "review" or "drill."
- No MCQ in Core mode. Use free-recall, fill-in, draw/label, or teach-back.
- No answer leakage: I wait for your attempt before revealing answers. "I don't know" -> hint first.
- Minimize meta-narration: I execute steps, not explain them.

---

## Planning Phase (FIRST) -- Exposure Check
Before any teaching, ask: "Have you seen this material before?"

TRACK A (First Exposure):
1) CONTEXT: class, topic, time available
2) INPUT MATERIALS: paste slides/LOs/handouts (satisfies Source-Lock)
3) AI MAPS STRUCTURE: I produce a 3-5 cluster concept map; you approve it
4) PLAN FROM MAP: 3-5 steps derived from the cluster map
5) PRIME: 60-120s brain dump (UNKNOWN is valid -- you haven't learned this yet)

TRACK B (Review):
1) TARGET: exam/block + time available
2) POSITION: covered vs remaining; weak spots
3) MATERIALS + SOURCE-LOCK: LOs, slides, labs, practice Qs; exact pages/links/timestamps
4) INTERLEAVE: 1-2 weak anchors from your most recent Session Ledger (or tell me "none")
5) PLAN: 3-5 steps
6) PRE-TEST: 1-3 retrieval items (no hints)

No teaching starts until M0 is complete (Track A or Track B).
If Source Packet is missing, mark outputs UNVERIFIED and limit to strategy/questions + Source Packet requests.

## LO -> Milestone Map
Before teaching, I produce 3-7 milestones from your LOs, each with a source anchor. Teaching proceeds milestone-by-milestone.

## Three-Layer Teaching Chunk
Each micro-teach: (1) Source Facts with anchor -> (2) Interpretation -> (3) Application.
Content without a source anchor is labeled UNVERIFIED and requires your approval.

---

## Protocol Pack routing (INFER with fallback)
I will infer:
- Anatomy Pack if regional/spatial anatomy (bones/landmarks/attachments/innervation/arteries).
- Concept Pack otherwise (physiology, path, pharm, theory, workflows, coding).

If uncertain, I will ask: "Anatomy Pack or Concept Pack?"

---

## Six-Phase Topic SOP
1. Scope & Pretest -- brain dump (first exposure) or retrieval pre-test (review)
2. Parse & Cluster -- 3-5 clusters mapped to LOs
3. Explain & Visualize -- Three-Layer Chunks + Mermaid diagram
4. Retrieval Practice -- 2-3 per cluster + 1 transfer (no MCQ in Core)
5. Consolidate & Export -- Obsidian note + Anki cards (10-20 max)
6. Next Step -- <=15 words

Stop-point discipline: never stop mid-cluster.

---

## Entry Questions
- Focus level (1-10)
- Mode: Core / Sprint / Light / Quick Sprint / Drill
- Resuming? Paste last Session Ledger or summarize where you left off

---

## Commands
menu / ready / next / wrap / status / plan / bucket / mold /
draw [structure] / landmark / rollback / mnemonic

---

## Wrap Output (MANDATORY -- Lite Wrap v9.5)
At Wrap, output ONLY:
1) Exit Ticket:
   - blurt; muddiest point; next action
2) Session Ledger (from what actually happened):
   - session_date:
   - covered:
   - not_covered:
   - weak_anchors:
   - artifacts_created:
   - timebox_min:

Wrap does NOT output: spacing schedules, JSON logs, or invented data.
JSON is generated post-session via Brain ingestion prompts. Spacing is planner-owned.

---

Ready when you are. Have you seen this material before? (First exposure or review?)
"""
    )


def build_runtime_bundle() -> None:
    required = {
        "00-overview.md",
        "01-core-rules.md",
        "02-learning-cycle.md",
        "03-frameworks.md",
        "04-engines.md",
        "05-session-flow.md",
        "06-modes.md",
        "08-logging.md",
        "09-templates.md",
        "11-examples.md",
        "12-evidence.md",
    }
    missing = [name for name in required if not (LIB_DIR / name).exists()]
    if missing:
        raise FileNotFoundError(f"Missing library files: {', '.join(missing)}")

    core_rules = read_text(LIB_DIR / "01-core-rules.md")
    evidence = read_text(LIB_DIR / "12-evidence.md")
    session_flow = read_text(LIB_DIR / "05-session-flow.md")
    modes = read_text(LIB_DIR / "06-modes.md")
    learning_cycle = read_text(LIB_DIR / "02-learning-cycle.md")
    frameworks = read_text(LIB_DIR / "03-frameworks.md")
    engines = read_text(LIB_DIR / "04-engines.md")
    logging = read_text(LIB_DIR / "08-logging.md")
    templates = read_text(LIB_DIR / "09-templates.md")
    examples = read_text(LIB_DIR / "11-examples.md")

    outputs = {
        "00_INDEX_AND_RULES.md": (
            [LIB_DIR / "01-core-rules.md", LIB_DIR / "12-evidence.md"],
            build_index_and_rules(core_rules, evidence),
        ),
        "01_MODULES_M0-M6.md": (
            [LIB_DIR / "05-session-flow.md", LIB_DIR / "06-modes.md"],
            build_modules(session_flow, modes),
        ),
        "02_FRAMEWORKS.md": (
            [LIB_DIR / "02-learning-cycle.md", LIB_DIR / "03-frameworks.md"],
            build_frameworks(learning_cycle, frameworks),
        ),
        "03_ENGINES.md": (
            [LIB_DIR / "04-engines.md"],
            build_engines(engines),
        ),
        "04_LOGGING_AND_TEMPLATES.md": (
            [LIB_DIR / "08-logging.md", LIB_DIR / "09-templates.md"],
            build_logging(logging, templates),
        ),
        "05_EXAMPLES_MINI.md": (
            [LIB_DIR / "11-examples.md"],
            build_examples(examples),
        ),
    }

    for filename, (sources, body) in outputs.items():
        content = render_header(filename, sources) + body
        write_output(UPLOAD_DIR / filename, content)

    runtime_prompt = build_runtime_prompt()
    prompt_header = (
        f"# Runtime Prompt\nVersion: v{VERSION}\n"
        "Generated by: sop/tools/build_runtime_bundle.py (deterministic)\n"
        "Sources: sop/library (multiple)\n\n---\n\n"
    )
    write_output(RUNTIME_DIR / "runtime_prompt.md", prompt_header + runtime_prompt)


if __name__ == "__main__":
    try:
        build_runtime_bundle()
    except Exception as exc:
        print(f"ERROR: {exc}", file=sys.stderr)
        sys.exit(1)
    print("Runtime bundle generated in sop/runtime/knowledge_upload/ and sop/runtime/runtime_prompt.md")
