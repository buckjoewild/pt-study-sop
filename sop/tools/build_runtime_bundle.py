#!/usr/bin/env python3
from __future__ import annotations

import re
import shutil
import sys
from pathlib import Path
from typing import Iterable, List

import yaml

VERSION = "9.5.2"

ROOT = Path(__file__).resolve().parents[2]
SOP_DIR = ROOT / "sop"
LIB_DIR = SOP_DIR / "library"
METHODS_DIR = LIB_DIR / "methods"
CHAINS_DIR = LIB_DIR / "chains"
META_DIR = LIB_DIR / "meta"
RUNTIME_DIR = SOP_DIR / "runtime"
UPLOAD_DIR = RUNTIME_DIR / "knowledge_upload"
GOLDEN_DIR = SOP_DIR / "tests" / "golden"


def rel(path: Path) -> str:
    return path.relative_to(ROOT).as_posix()


def read_text(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def normalize(text: str) -> str:
    return text.replace("\r\n", "\n").replace("\r", "\n").strip()


def strip_relative_links(text: str) -> str:
    def repl(match: re.Match[str]) -> str:
        label = match.group(1)
        link = match.group(2)
        if re.match(r"^(https?://|mailto:)", link):
            return match.group(0)
        return label

    return re.sub(r"\[([^\]]+)\]\(([^)]+)\)", repl, text)


def replace_local_refs(text: str) -> str:
    replacements = {
        "sop/src/templates/retrospective_timetable.md": "retrospective timetable (see Templates section)",
        "sop/src/templates/post_lecture_elaboration_prompts.md": "post-lecture elaboration prompts (see Templates section)",
        "sop/logging_schema_v9.3.md": "logging schema (see Logging section)",
        "logging_schema_v9.3.md": "logging schema (see Logging section)",
        "sop/src/workload/rotational_interleaving_3plus2.md": "3+2 rotational interleaving (see M0 Planning)",
        "sop/master_rotational_interleaving_system.md": "3+2 rotational interleaving (see M0 Planning)",
        "09-templates.md": "Templates section",
        "06-modes.md": "Modes section",
    }
    for key, value in replacements.items():
        text = text.replace(key, value)
    return text


def sanitize(text: str) -> str:
    text = normalize(text)
    text = strip_relative_links(text)
    text = replace_local_refs(text)
    return text


def extract_section(text: str, heading: str) -> str:
    text = normalize(text)
    lines = text.split("\n")
    for i, line in enumerate(lines):
        if line.strip() == heading:
            level = len(line.split()[0])
            start = i
            end = len(lines)
            for j in range(i + 1, len(lines)):
                candidate = lines[j].strip()
                if candidate.startswith("#"):
                    candidate_level = len(candidate.split()[0])
                    if candidate_level <= level:
                        end = j
                        break
            return "\n".join(lines[start:end]).strip()
    raise ValueError(f"Heading not found: {heading}")


def join_sections(text: str, headings: Iterable[str]) -> str:
    return "\n\n".join(extract_section(text, heading) for heading in headings)


def find_wrap_heading(text: str) -> str:
    text = normalize(text)
    lines = text.split("\n")
    prefix = "## M6: Wrap"
    for line in lines:
        stripped = line.strip()
        if stripped.startswith(prefix):
            print(f"Wrap section found: {stripped}")
            return stripped
    raise ValueError(
        "M6 Wrap heading not found. Acceptable headings: "
        "'## M6: Wrap (Close and Schedule)', '## M6: Wrap', "
        "or any heading starting with '## M6: Wrap'."
    )


def render_header(filename: str, sources: List[Path]) -> str:
    sources_block = "\n".join(f"- {rel(path)}" for path in sources)
    return (
        f"# Runtime Bundle: {filename}\n"
        f"Version: v{VERSION}\n"
        "Generated by: sop/tools/build_runtime_bundle.py (deterministic)\n"
        f"Sources:\n{sources_block}\n\n---\n\n"
    )


def render_source_block(source_path: Path, content: str) -> str:
    return f"## Source: {rel(source_path)}\n\n{sanitize(content)}\n"


def write_output(path: Path, content: str) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content.strip() + "\n", encoding="utf-8")


def build_index_and_rules(core_rules: str, evidence: str) -> str:
    core_extract = join_sections(
        core_rules,
        [
            "## Session Rules",
            "## Content Rules",
            "## Evidence Nuance Rules",
            "## Logging Rules",
            "## No-Skip Rules (Summary)",
        ],
    )
    notebooklm = extract_section(evidence, "## NotebookLM Bridge")

    additions = """
## Source of Truth
- Canonical content lives in `sop/library/` and is read-only.
- Runtime files in `sop/runtime/knowledge_upload/` are generated. Do not edit them directly.

## Bundle Index (upload in order)
1) 00_INDEX_AND_RULES.md
2) 01_MODULES_M0-M6.md
3) 02_FRAMEWORKS.md
4) 03_ENGINES.md
5) 04_LOGGING_AND_TEMPLATES.md
6) 05_EXAMPLES_MINI.md
7) 06_METHODS.md

## Canonical Library Map (current filenames)
- 02-learning-cycle.md (PEIRRO + KWIK)
- 03-frameworks.md (H/M/Y/L)
- 04-engines.md
- 05-session-flow.md (M0-M6)
- 06-modes.md
- 08-logging.md
- 09-templates.md
- 11-examples.md
- 12-evidence.md

## Multi-Domain Topic Prefix + Engine Router (schema-safe)
- The `topic` field must be prefixed with: `[DPT]` or `[Startup]` or `[Other]`.
- Engine router:
  - If `[DPT]` and regional/spatial anatomy, use the Anatomy Engine.
  - Otherwise use the Concept Engine.
- Do not add new JSON keys for domain routing.

## UNVERIFIED Behavior (no refusal)
- If sources are missing or no NotebookLM Source Packet is provided, mark outputs **UNVERIFIED**.
- Limit output to strategy, questions, and planning until sources are provided.

## Dashboard Ingest: `anki_cards` Encoding
- Enhanced JSON field `anki_cards` is a semicolon-separated list.
- Each card uses the format: `Front|||Back|||TagsCSV|||Deck`.
- Avoid semicolons inside Front/Back.
- Deck may be `AUTO` to route by topic prefix.
"""

    return (
        sanitize(additions)
        + "\n\n"
        + render_source_block(LIB_DIR / "01-core-rules.md", core_extract)
        + "\n"
        + render_source_block(LIB_DIR / "12-evidence.md", notebooklm)
    )


def build_modules(session_flow: str, modes: str) -> str:
    wrap_heading = find_wrap_heading(session_flow)
    headings = [
        "## 60-Second Quick Start",
        "## M0: Planning",
        "## M1: Entry",
        "## M2: Prime (Map the Territory)",
        "## M3: Encode (Attach Meaning)",
        "## M4: Build (Practice and Transfer)",
        wrap_heading,
        "## Quick Reference: Session Flow",
    ]
    session_extract = join_sections(session_flow, headings)
    return (
        render_source_block(LIB_DIR / "05-session-flow.md", session_extract)
        + "\n"
        + render_source_block(LIB_DIR / "06-modes.md", modes)
    )


def build_frameworks(learning_cycle: str, frameworks: str) -> str:
    return (
        render_source_block(LIB_DIR / "02-learning-cycle.md", learning_cycle)
        + "\n"
        + render_source_block(LIB_DIR / "03-frameworks.md", frameworks)
    )


def build_engines(engines: str) -> str:
    router = """
## Engine Router (Multi-Domain)
- Topic prefix required: `[DPT]` / `[Startup]` / `[Other]`.
- If `[DPT]` and regional/spatial anatomy: use Anatomy Engine.
- Otherwise: use Concept Engine.
- This is a routing convention only; no schema keys are added.
"""
    return sanitize(router) + "\n\n" + render_source_block(LIB_DIR / "04-engines.md", engines)


def build_logging(logging: str, templates: str) -> str:
    additions = """
## Runtime Additions (v9.3)

### Topic Prefix (multi-domain)
- `topic` must start with `[DPT]`, `[Startup]`, or `[Other]`.

### Dashboard `anki_cards` Encoding
- `anki_cards` remains a semicolon-separated list.
- Each card entry is: `Front|||Back|||TagsCSV|||Deck`.
- Avoid semicolons inside Front/Back.
- Deck may be `AUTO` to route by topic prefix.
"""
    return (
        sanitize(additions)
        + "\n\n"
        + render_source_block(LIB_DIR / "08-logging.md", logging)
        + "\n"
        + render_source_block(LIB_DIR / "09-templates.md", templates)
    )


def build_examples(examples: str) -> str:
    headings = [
        "## Command Reference",
        "## Example: Session Start (Planning)",
        "## Example: Core Mode Teaching (First Exposure — Three-Layer Chunks + KWIK)",
        "## Example: Sprint Mode (Fail-First)",
        "## Example: Wrap Output",
    ]
    sections: list[str] = []
    missing: list[str] = []
    for heading in headings:
        try:
            sections.append(extract_section(examples, heading))
        except ValueError:
            missing.append(heading)
    if missing:
        print(
            "WARNING: Missing example headings: " + ", ".join(missing),
            file=sys.stderr,
        )
    extract = "\n\n".join(sections).strip()
    return render_source_block(LIB_DIR / "11-examples.md", extract)


def find_heading(text: str, prefix: str) -> str:
    """Find the actual heading line that starts with the given prefix."""
    for line in normalize(text).split("\n"):
        if line.strip().startswith(prefix):
            return line.strip()
    raise ValueError(f"No heading starting with: {prefix}")


def build_methods(methods_text: str) -> str:
    """Extract compact method library summary for knowledge upload."""
    headings = [
        "## §1 Purpose",
        "## §2 Method Block Schema",
        find_heading(methods_text, "## §2.1 Block Catalog"),
        find_heading(methods_text, "## §4 Template Chains"),
        "## §6 Context Dimensions",
    ]
    sections: list[str] = []
    missing: list[str] = []
    for heading in headings:
        try:
            sections.append(extract_section(methods_text, heading))
        except ValueError:
            missing.append(heading)
    if missing:
        print(
            "WARNING: Missing method headings: " + ", ".join(missing),
            file=sys.stderr,
        )
    extract = "\n\n".join(sections).strip()
    return render_source_block(LIB_DIR / "15-method-library.md", extract)


def build_runtime_prompt() -> str:
    return sanitize(
        f"""Structured Architect v{VERSION} active.
Role: guide active construction; enforce planning gates; prevent phantom outputs; adapt to readiness.

## Non-negotiable rules
- Planning gate: Exposure Check first. No teaching until M0 is complete (Track A or Track B).
- Source-Lock: factual teaching requires learner sources; if missing -> label UNVERIFIED and do strategy/questions only.
- Seed-Lock (ask-first): you attempt seeds first; AI suggests only if you ask.
- No Phantom Outputs: never invent hooks/cards/metrics/schedules/coverage. If not done -> NOT DONE / UNKNOWN / NONE.
- Level gating: L2 teach-back before L4 detail.

## Pacing rules
- Teaching Rule: when delivering content (M3 Encode, Phase 3), I teach a complete Three-Layer Chunk (Source Facts + Interpretation + Application) as ONE message. I end with ONE comprehension question (why/how/apply). I do NOT ask you to repeat what I just said.
- Retrieval Rule: when testing (M4 Build, Phase 4, Sprint/Drill), each message = ONE question. Wait for your answer. Brief feedback. Next question.
- Comprehension over parrot-back: after teaching, I ask WHY/HOW/APPLY questions. I NEVER ask "Can you repeat that?" or "What did I just say?"
- KWIK during encoding: when I encounter a new term in M3, I run KWIK (Sound -> Function -> Image -> Resonance -> Lock) before the next chunk. This happens DURING teaching, not at Wrap.
- Sustain teaching: I teach a full cluster (2-4 chunks) before switching to retrieval practice.
- Continuation: after your answer -> brief feedback -> next single step. Never stall or end without a next action.
- Default mode: FIRST EXPOSURE (teach-first) unless you say "review" or "drill."
- No MCQ in Core mode. Use free-recall, fill-in, draw/label, or teach-back.
- No answer leakage: I wait for your attempt before revealing answers. "I don't know" -> hint first.
- Minimize meta-narration: I execute steps, not explain them.

---

## Planning Phase (FIRST) -- Exposure Check
Before any teaching, ask: "Have you seen this material before?"

TRACK A (First Exposure):
1) CONTEXT: class, topic, time available
2) INPUT MATERIALS: paste slides/LOs/handouts (satisfies Source-Lock)
3) AI MAPS STRUCTURE: I produce a 3-5 cluster concept map; you approve it
4) PLAN FROM MAP: 3-5 steps derived from the cluster map
5) PRIME: 60-120s brain dump (UNKNOWN is valid -- you haven't learned this yet)

TRACK B (Review):
1) TARGET: exam/block + time available
2) POSITION: covered vs remaining; weak spots
3) MATERIALS + SOURCE-LOCK: LOs, slides, labs, practice Qs; exact pages/links/timestamps
4) INTERLEAVE: 1-2 weak anchors from your most recent Session Ledger (or tell me "none")
5) PLAN: 3-5 steps
6) PRE-TEST: 1-3 retrieval items (no hints)

No teaching starts until M0 is complete (Track A or Track B).
If Source Packet is missing, mark outputs UNVERIFIED and limit to strategy/questions + Source Packet requests.

## LO -> Milestone Map
Before teaching, I produce 3-7 milestones from your LOs, each with a source anchor. Teaching proceeds milestone-by-milestone.

## Three-Layer Teaching Chunk
Each micro-teach: (1) Source Facts with anchor -> (2) Interpretation -> (3) Application.
Content without a source anchor is labeled UNVERIFIED and requires your approval.

---

## Protocol Pack routing (INFER with fallback)
I will infer:
- Anatomy Pack if regional/spatial anatomy (bones/landmarks/attachments/innervation/arteries).
- Concept Pack otherwise (physiology, path, pharm, theory, workflows, coding).

If uncertain, I will ask: "Anatomy Pack or Concept Pack?"

---

## Six-Phase Topic SOP
1. Scope & Pretest -- brain dump (first exposure) or retrieval pre-test (review)
2. Parse & Cluster -- 3-5 clusters mapped to LOs
3. Explain & Visualize -- Three-Layer Chunks + Mermaid diagram
4. Retrieval Practice -- 2-3 per cluster + 1 transfer (no MCQ in Core)
5. Consolidate & Export -- Obsidian note + Anki cards (10-20 max)
6. Next Step -- <=15 words

Stop-point discipline: never stop mid-cluster.

---

## Entry Questions
- Focus level (1-10)
- Mode: Core / Sprint / Light / Quick Sprint / Drill
- Resuming? Paste last Session Ledger or summarize where you left off

---

## Commands
menu / ready / next / wrap / status / plan / bucket / mold /
draw [structure] / landmark / rollback / mnemonic

---

## Wrap Output (MANDATORY -- Lite Wrap v9.5)
At Wrap, output ONLY:
1) Exit Ticket:
   - blurt; muddiest point; next action
2) Session Ledger (from what actually happened):
   - session_date:
   - covered:
   - not_covered:
   - weak_anchors:
   - artifacts_created:
   - timebox_min:

Wrap does NOT output: spacing schedules, JSON logs, or invented data.
JSON is generated post-session via Brain ingestion prompts. Spacing is planner-owned.

---

Ready when you are. Have you seen this material before? (First exposure or review?)
"""
    )


def build_custom_instructions() -> str:
    """Extract the code block from 13-custom-gpt-system-instructions.md."""
    source = read_text(LIB_DIR / "13-custom-gpt-system-instructions.md")
    # Extract content between first ``` markers
    blocks = re.findall(r"```\n(.*?)```", source, re.DOTALL)
    if not blocks:
        raise ValueError("No code block found in 13-custom-gpt-system-instructions.md")
    header = (
        f"# Custom Instructions (v{VERSION})\n"
        "# Paste everything below this line into CustomGPT \"Instructions\" field.\n"
        "# Source of truth: sop/library/13-custom-gpt-system-instructions.md\n"
        f"# Generated by: sop/tools/build_runtime_bundle.py\n\n"
    )
    return header + blocks[0].strip() + "\n"


# ---------------------------------------------------------------------------
# YAML-based method library generation
# ---------------------------------------------------------------------------

# Category display order (PEIRRO sequence)
CATEGORY_ORDER = ["prepare", "encode", "retrieve", "interrogate", "refine", "overlearn"]

# Category labels for markdown headings
CATEGORY_LABELS = {
    "prepare": "Prepare",
    "encode": "Encode",
    "retrieve": "Retrieve",
    "interrogate": "Interrogate",
    "refine": "Refine",
    "overlearn": "Overlearn",
}

# Chain name→number mapping (preserves original numbering)
CHAIN_NUMBERS = {
    "First Exposure (Core)": 1,
    "Review Sprint": 2,
    "Quick Drill": 3,
    "Anatomy Deep Dive": 4,
    "Low Energy": 5,
    "Exam Prep": 6,
    "Clinical Reasoning": 7,
    "Mastery Review": 8,
    "Dense Anatomy Intake": 9,
    "Pathophysiology Intake": 10,
    "Clinical Reasoning Intake": 11,
    "Quick First Exposure": 12,
    "Visual Encoding": 13,
}

# Chain groupings for section headers
CHAIN_GROUPS = {
    "Core Chains": [
        "First Exposure (Core)", "Review Sprint", "Quick Drill",
        "Anatomy Deep Dive", "Low Energy", "Exam Prep",
        "Clinical Reasoning", "Mastery Review",
    ],
    "Intake-Focused Chains": [
        "Dense Anatomy Intake", "Pathophysiology Intake",
        "Clinical Reasoning Intake", "Quick First Exposure",
    ],
    "Visualization Chains": ["Visual Encoding"],
}


def _yaml_has_methods() -> bool:
    """Check if YAML method specs exist (auto-detection)."""
    return METHODS_DIR.exists() and any(METHODS_DIR.glob("*.yaml"))


def _load_yaml_methods() -> list[dict]:
    """Load all method YAML files sorted by ID."""
    methods = []
    for path in sorted(METHODS_DIR.glob("*.yaml")):
        data = yaml.safe_load(path.read_text(encoding="utf-8"))
        if data:
            methods.append(data)
    return methods


def _load_yaml_chains() -> list[dict]:
    """Load all chain YAML files sorted by ID."""
    chains = []
    for path in sorted(CHAINS_DIR.glob("*.yaml")):
        data = yaml.safe_load(path.read_text(encoding="utf-8"))
        if data:
            chains.append(data)
    return chains


def _method_id_to_name(methods: list[dict]) -> dict[str, str]:
    """Build {method_id: name} lookup."""
    return {m["id"]: m["name"] for m in methods}


def _format_evidence_short(method: dict) -> str:
    """Format evidence for the compact block catalog table."""
    ev = method.get("evidence")
    raw = method.get("evidence_raw", "")
    if ev and isinstance(ev, dict):
        citation = ev.get("citation", "")
        finding = ev.get("finding", "")
        if citation and finding:
            return f"{citation}; {finding}"
    if raw:
        return raw
    return ""


def _render_block_catalog(methods: list[dict]) -> str:
    """Render §2.1 Block Catalog section matching the hand-written format."""
    # Group by category
    by_cat: dict[str, list[dict]] = {}
    for m in methods:
        cat = m["category"]
        by_cat.setdefault(cat, []).append(m)

    total = len(methods)
    lines = [f"## §2.1 Block Catalog ({total} blocks)", ""]

    for cat in CATEGORY_ORDER:
        cat_methods = by_cat.get(cat, [])
        if not cat_methods:
            continue
        label = CATEGORY_LABELS.get(cat, cat.title())
        lines.append(f"### {label} ({len(cat_methods)} blocks)")
        lines.append("| Block | Duration | Energy | Evidence |")
        lines.append("|-------|----------|--------|----------|")
        for m in cat_methods:
            name = m["name"]
            dur = f"{m['default_duration_min']} min"
            energy = m["energy_cost"]
            evidence = _format_evidence_short(m)
            lines.append(f"| {name} | {dur} | {energy} | {evidence} |")
        lines.append("")

    return "\n".join(lines).rstrip()


def _format_context_tags(tags: dict) -> str:
    """Format context_tags dict into a readable string."""
    parts = []
    if "class_type" in tags:
        parts.append(tags["class_type"].replace("_", " ").title())
    if "stage" in tags:
        parts.append(tags["stage"].replace("_", " "))
    if "energy" in tags:
        parts.append(f"{tags['energy']} energy")
    if "time_available" in tags:
        parts.append(f"{tags['time_available']} min")
    return ", ".join(parts) if parts else ""


def _render_template_chains(chains: list[dict], id_to_name: dict[str, str]) -> str:
    """Render §4 Template Chains section matching the hand-written format."""
    total = len(chains)
    lines = [f"## §4 Template Chains ({total} chains)", ""]

    # Build name→chain lookup
    chain_by_name: dict[str, dict] = {c["name"]: c for c in chains}

    for group_title, chain_names in CHAIN_GROUPS.items():
        lines.append(f"### {group_title}")
        lines.append("")
        for cname in chain_names:
            chain = chain_by_name.get(cname)
            if not chain:
                continue
            num = CHAIN_NUMBERS.get(cname, "?")
            # Resolve block IDs to names
            block_names = []
            for bid in chain.get("blocks", []):
                block_names.append(id_to_name.get(bid, bid))
            blocks_str = " → ".join(block_names)
            context_str = _format_context_tags(chain.get("context_tags", {}))
            desc = chain.get("description", "")

            lines.append(f"#### {num}. {cname}")
            lines.append(f"**Blocks:** {blocks_str}")
            lines.append(f"**Context:** {context_str}")
            lines.append(f"**Use for:** {desc}")
            # Special note for First Exposure chain
            if cname == "First Exposure (Core)":
                lines.append(
                    "**Note:** Retrieval (Free Recall) comes before generative "
                    "encoding (KWIK Hook) per Potts & Shanks (2022) — lower "
                    "cognitive load, higher gains."
                )
            lines.append("")

    return "\n".join(lines).rstrip()


def build_methods_from_yaml() -> str:
    """Generate 15-method-library.md content from YAML specs.

    Returns the full markdown string. Preserves the exact heading structure
    required by build_methods() (the generator contract).
    """
    methods = _load_yaml_methods()
    chains = _load_yaml_chains()
    id_to_name = _method_id_to_name(methods)

    # Load taxonomy for category descriptions
    taxonomy_path = META_DIR / "taxonomy.yaml"
    taxonomy = {}
    if taxonomy_path.exists():
        taxonomy = yaml.safe_load(taxonomy_path.read_text(encoding="utf-8")) or {}
    categories = taxonomy.get("categories", {})

    # Build category description lines
    cat_descriptions = []
    for i, cat in enumerate(CATEGORY_ORDER, 1):
        info = categories.get(cat, {})
        label = info.get("label", cat.title())
        desc = info.get("description", "")
        # List method names for this category
        cat_methods = [m["name"].lower() for m in methods if m["category"] == cat]
        methods_str = ", ".join(cat_methods)
        cat_descriptions.append(
            f"{i}. **{label}** — {desc} (e.g., {methods_str})"
        )

    sections = []

    # §1 Purpose
    sections.append("""# 15 — Composable Method Library

## §1 Purpose

The Composable Method Library provides reusable, evidence-backed method blocks and pre-built chains for study sessions. Method blocks are atomic study activities (e.g., brain dump, teach-back, retrieval drill). Chains are ordered sequences of blocks designed for specific contexts (e.g., first exposure, exam prep, low energy).

**Goals:**
- **Consistency** — Apply proven methods across sessions
- **Adaptability** — Select chains based on context (class type, stage, energy, time)
- **Evidence** — Every block cites research backing its effectiveness
- **Data** — Rate effectiveness to improve recommendations over time

---""")

    # §2 Method Block Schema
    cat_block = "\n".join(cat_descriptions)
    sections.append(f"""## §2 Method Block Schema

Each method block represents a single study activity.

**Fields:**

| Field | Type | Description |
|-------|------|-------------|
| `name` | string | Block name (e.g., "Brain Dump", "Teach-Back") |
| `category` | enum | One of 6 PEIRRO phases (see below) |
| `description` | string | What the block does |
| `duration` | number | Typical minutes required |
| `energy_cost` | enum | `low` / `medium` / `high` |
| `best_stage` | enum | `first_exposure` / `review` / `exam_prep` / `consolidation` |
| `tags` | array | Descriptors (e.g., `["retrieval", "active"]`) |
| `evidence` | string | Research citation (Author, Year; brief finding) |

**Categories (PEIRRO phases):**

{cat_block}

**Evidence citation format:** `Author (Year); brief finding`

---""")

    # §2.1 Block Catalog
    sections.append(_render_block_catalog(methods))
    sections.append("---")

    # §3 Chain Schema
    sections.append("""## §3 Chain Schema

A chain is an ordered sequence of method blocks with context tags.

**Fields:**

| Field | Type | Description |
|-------|------|-------------|
| `chain_id` | string | Unique identifier |
| `name` | string | Chain name (e.g., "First Exposure Core") |
| `blocks` | array | Ordered list of block names |
| `context_tags` | object | Recommended context (see §6) |
| `description` | string | When to use this chain |

---""")

    # §4 Template Chains
    sections.append(_render_template_chains(chains, id_to_name))
    sections.append("---")

    # §5 Rating Protocol
    sections.append("""## §5 Rating Protocol

After each session using a method chain, rate its effectiveness.

**Post-Session Rating (captured during Wrap):**

| Field | Scale | Description |
|-------|-------|-------------|
| `effectiveness` | 1-5 | How well did the chain work for this material? |
| `engagement` | 1-5 | How engaged/focused were you? |
| `context_tags` | object | Actual context (class_type, stage, energy, time_available) |
| `notes` | string | Optional free text (e.g., "KWIK worked well; Teach-Back felt rushed") |

**Rating Scale:**

- **1** — Ineffective / disengaged
- **2** — Somewhat ineffective / low engagement
- **3** — Neutral / moderate engagement
- **4** — Effective / high engagement
- **5** — Highly effective / fully engaged

**Capture in Session Ledger:**

Add to `artifacts_created` if a method chain was used:
```
method_chain: [chain_id]; effectiveness: [1-5]; engagement: [1-5]
```

---""")

    # §6 Context Dimensions
    sections.append("""## §6 Context Dimensions

Context tags describe when a chain is appropriate.

| Dimension | Values | Description |
|-----------|--------|-------------|
| `class_type` | `anatomy` / `physiology` / `pathology` / `pharmacology` / `clinical` / `general` | Subject type |
| `stage` | `first_exposure` / `review` / `exam_prep` | Learning stage |
| `energy` | `low` / `medium` / `high` | Focus/motivation level (1-10 scale mapped to low=1-4, medium=5-7, high=8-10) |
| `time_available` | number | Minutes available for session |

**Matching Logic:**

Brain recommends chains where context tags align with current session context. Exact matches preferred; partial matches allowed.

---""")

    # §7 Brain Integration
    sections.append("""## §7 Brain Integration

Brain stores and analyzes method chain data.

**Tables:**

1. **method_blocks** — All available blocks (with evidence citations)
2. **method_chains** — Pre-built and custom chains
3. **method_ratings** — Post-session ratings per block and chain

**Analytics:**

- **Effectiveness stats** — Average rating per chain, per context
- **Usage frequency** — Which chains are used most often
- **Anomaly detection** — Flag chains with low ratings in specific contexts
- **Recommendations** — Suggest chains based on session context and historical performance

---""")

    # §8 Scholar Integration
    sections.append("""## §8 Scholar Integration

Scholar questions chain effectiveness and proposes improvements.

**Research Questions:**

1. Which blocks correlate with high retention (from RSR data)?
2. Do certain chains work better for specific class types?
3. Are there context patterns where effectiveness is consistently low?
4. Can we predict optimal chain selection based on past sessions?

**Outputs:**

- **Chain Optimization Proposals** — Reorder blocks, swap blocks, adjust durations
- **New Chain Designs** — Propose chains for underserved contexts
- **A/B Test Plans** — Compare variant chains in similar contexts

---""")

    # Cross-References
    sections.append("""## Cross-References

- **Core Rules:** `01-core-rules.md` (planning, source-lock, seed-lock gates apply during method execution)
- **Session Flow:** `05-session-flow.md` (method chains run inside M2-M4; selection occurs during M0 Planning)
- **Modes:** `06-modes.md` (chains can be mode-specific; e.g., Sprint chains use retrieval-first blocks)
- **Logging:** `08-logging.md` (method_chain field added to Session Ledger and Enhanced JSON)
- **Templates:** `09-templates.md` (method_chain added to Session Ledger template)

---""")

    # Implementation Notes
    sections.append("""## Implementation Notes

- Method chains are **optional**. Sessions can proceed without selecting a chain.
- Chains are **composable** — blocks can be reordered or omitted as needed.
- **Ad-hoc chains** can be built during M0 Planning if no template fits.
- Rating is **opt-in** but recommended for data-driven improvement.
- All blocks include evidence citations. Use `--force` re-seed to update.
- Use `--migrate` flag to update categories on an existing database without wiping data.""")

    return "\n\n".join(sections) + "\n"


def _write_generated_method_library() -> None:
    """Generate 15-method-library.md from YAML and write to disk."""
    content = build_methods_from_yaml()
    write_output(LIB_DIR / "15-method-library.md", content)
    print(f"  [OK] Generated {rel(LIB_DIR / '15-method-library.md')} from YAML")


def _update_golden_files() -> None:
    """Copy current generated outputs to golden test baselines."""
    GOLDEN_DIR.mkdir(parents=True, exist_ok=True)
    src_lib = LIB_DIR / "15-method-library.md"
    src_runtime = UPLOAD_DIR / "06_METHODS.md"
    if src_lib.exists():
        shutil.copy2(src_lib, GOLDEN_DIR / "15-method-library.golden.md")
        print(f"  [OK] Updated golden: 15-method-library.golden.md")
    if src_runtime.exists():
        shutil.copy2(src_runtime, GOLDEN_DIR / "06_METHODS.golden.md")
        print(f"  [OK] Updated golden: 06_METHODS.golden.md")


def build_runtime_bundle() -> None:
    required = {
        "00-overview.md",
        "01-core-rules.md",
        "02-learning-cycle.md",
        "03-frameworks.md",
        "04-engines.md",
        "05-session-flow.md",
        "06-modes.md",
        "08-logging.md",
        "09-templates.md",
        "11-examples.md",
        "12-evidence.md",
        "13-custom-gpt-system-instructions.md",
        "15-method-library.md",
    }
    missing = [name for name in required if not (LIB_DIR / name).exists()]
    if missing:
        raise FileNotFoundError(f"Missing library files: {', '.join(missing)}")

    core_rules = read_text(LIB_DIR / "01-core-rules.md")
    evidence = read_text(LIB_DIR / "12-evidence.md")
    session_flow = read_text(LIB_DIR / "05-session-flow.md")
    modes = read_text(LIB_DIR / "06-modes.md")
    learning_cycle = read_text(LIB_DIR / "02-learning-cycle.md")
    frameworks = read_text(LIB_DIR / "03-frameworks.md")
    engines = read_text(LIB_DIR / "04-engines.md")
    logging = read_text(LIB_DIR / "08-logging.md")
    templates = read_text(LIB_DIR / "09-templates.md")
    examples = read_text(LIB_DIR / "11-examples.md")
    methods = read_text(LIB_DIR / "15-method-library.md")

    outputs = {
        "00_INDEX_AND_RULES.md": (
            [LIB_DIR / "01-core-rules.md", LIB_DIR / "12-evidence.md"],
            build_index_and_rules(core_rules, evidence),
        ),
        "01_MODULES_M0-M6.md": (
            [LIB_DIR / "05-session-flow.md", LIB_DIR / "06-modes.md"],
            build_modules(session_flow, modes),
        ),
        "02_FRAMEWORKS.md": (
            [LIB_DIR / "02-learning-cycle.md", LIB_DIR / "03-frameworks.md"],
            build_frameworks(learning_cycle, frameworks),
        ),
        "03_ENGINES.md": (
            [LIB_DIR / "04-engines.md"],
            build_engines(engines),
        ),
        "04_LOGGING_AND_TEMPLATES.md": (
            [LIB_DIR / "08-logging.md", LIB_DIR / "09-templates.md"],
            build_logging(logging, templates),
        ),
        "05_EXAMPLES_MINI.md": (
            [LIB_DIR / "11-examples.md"],
            build_examples(examples),
        ),
        "06_METHODS.md": (
            [LIB_DIR / "15-method-library.md"],
            build_methods(methods),
        ),
    }

    for filename, (sources, body) in outputs.items():
        content = render_header(filename, sources) + body
        write_output(UPLOAD_DIR / filename, content)

    runtime_prompt = build_runtime_prompt()
    prompt_header = (
        f"# Runtime Prompt\nVersion: v{VERSION}\n"
        "Generated by: sop/tools/build_runtime_bundle.py (deterministic)\n"
        "Sources: sop/library (multiple)\n\n---\n\n"
    )
    write_output(RUNTIME_DIR / "runtime_prompt.md", prompt_header + runtime_prompt)

    custom_instructions = build_custom_instructions()
    write_output(RUNTIME_DIR / "custom_instructions.md", custom_instructions)


if __name__ == "__main__":
    update_golden = "--update-golden" in sys.argv

    try:
        # Auto-detect: if YAML method specs exist, generate 15-method-library.md from them
        if _yaml_has_methods():
            print("[YAML] Generating 15-method-library.md from YAML specs...")
            _write_generated_method_library()
        else:
            print("[MD] Using hand-written 15-method-library.md (no YAML specs found)")

        build_runtime_bundle()

        if update_golden:
            print("[GOLDEN] Updating golden test baselines...")
            _update_golden_files()

    except Exception as exc:
        print(f"ERROR: {exc}", file=sys.stderr)
        sys.exit(1)
    print("Runtime bundle generated in sop/runtime/knowledge_upload/ and sop/runtime/runtime_prompt.md")
